{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deploy <font color='#6957FF'>COMET Quality Estimation</font> Model Package from AWS Marketplace\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMET (Cross-lingual Optimized Metric for Evaluation of Translation)** is a neural framework for training multilingual machine translation evaluation models. This package provides a commercially-friendly offering of the **wmt22-cometkiwi-da** model, a direct assessment (DA) model trained on WMT22 data and [made available at HuggingFace](https://huggingface.co/Unbabel/wmt22-cometkiwi-da) for non-commercial use.\n",
    "\n",
    "This sample notebook shows you how to deploy <font color='#C9FF33'>[COMETKiwi](https://aws.amazon.com/marketplace/pp/prodview-k5lgwkzc62j5u)</font> using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This model package only supports SageMaker Realtime Inference.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "2. To deploy this ML model successfully, ensure that:\n",
    "    - Either your IAM role has these three permissions, and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        - **aws-marketplace:ViewSubscriptions**\n",
    "        - **aws-marketplace:Unsubscribe**\n",
    "        - **aws-marketplace:Subscribe**  \n",
    "    - or your AWS account has a subscription to <font color='#C9FF33'>[COMETKiwi](https://aws.amazon.com/marketplace/pp/prodview-k5lgwkzc62j5u)</font>. If so, skip step [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "3. Before running this notebook, please make sure you are using a virtualenv with the notebook so that the dependencies are installed in the virtual env.\n",
    "4. Create a `.env` file from `.env_example` and set the appropriate values for AWS credentials and for AWS Region.\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "3. [Example use cases](#3.-Example-use-cases)\n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (by using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page <font color='#C9FF33'>[COMETKiwi](https://aws.amazon.com/marketplace/pp/prodview-k5lgwkzc62j5u)</font> in AWS Marketplace.\n",
    "2. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "3. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms.\n",
    "4. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, [see their documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install sagemaker~=2.235.0 python-dotenv~=1.0.0\n",
    "import json\n",
    "from sagemaker import ModelPackage, Predictor, Session\n",
    "from sagemaker import deserializers, get_execution_role, serializers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:30:08.879574Z",
     "start_time": "2024-12-06T15:30:08.877323Z"
    }
   },
   "source": [
    "# Set model package ARN\n",
    "region = \"us-east-1\"\n",
    "model_package_arn = f\"arn:aws:sagemaker:{region}:571600842260:model-package/comet-wmt22-cometkiwi-da\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your default execution role has permissions necessary as specified in the pre-requisites or set the value of role directly to the suitable role."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "session = Session()\n",
    "role = get_execution_role(session)  # Or directly specify a suitable role"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:30:25.642992Z",
     "start_time": "2024-12-06T15:30:25.641243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Choose an instance type to run the model\n",
    "instance_type = \"ml.m5.xlarge\"  # Adjust based on your needs"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:30:27.405519Z",
     "start_time": "2024-12-06T15:30:27.402938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = model_package_arn.split(\"/\")[-1]\n",
    "\n",
    "# Create a deployable model from the model package\n",
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "print(f\"{model_name=}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='comet-wmt22-cometkiwi-da'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint\n",
    "This process takes several minutes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=model_name,\n",
    "    container_startup_health_check_timeout=300,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:41:43.678449Z",
     "start_time": "2024-12-06T15:41:43.676328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example input for quality estimation\n",
    "sample_input = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"src\": \"The cat sat on the mat.\",\n",
    "            \"mt\": \"Le chat était assis sur le tapis.\",\n",
    "        },\n",
    "        {\n",
    "            \"src\": \"I love programming in Python.\",\n",
    "            \"mt\": \"J'aime programmer en Python.\",\n",
    "        },\n",
    "        {\n",
    "            \"src\": \"The weather is beautiful today.\",\n",
    "            \"mt\": \"Il fait beau aujourd'hui.\",\n",
    "        }\n",
    "    ],\n",
    "    \"batch_size\": 3\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### C. Perform real-time inference"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:41:47.887450Z",
     "start_time": "2024-12-06T15:41:47.379409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=model_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")\n",
    "\n",
    "response = predictor.predict(sample_input)\n",
    "print(json.dumps(response, indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scores\": [\n",
      "    0.8695598840713501,\n",
      "    0.8979955315589905,\n",
      "    0.8807777762413025\n",
      "  ],\n",
      "  \"system_score\": 0.882777730623881,\n",
      "  \"message\": \"Prediction successful\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example use cases\n",
    "\n",
    "### Multiple language pairs\n",
    "COMET can evaluate translations across multiple language pairs in a single batch:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:41:56.837508Z",
     "start_time": "2024-12-06T15:41:56.282948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multilingual_input = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"src\": \"A group of researchers has launched a new model for translation-related tasks.\",\n",
    "            \"mt\": \"Un grupo de investigadores ha lanzado un nuevo modelo para tareas relacionadas con la traducción.\",\n",
    "        },\n",
    "        {\n",
    "            \"src\": \"The new model is based on a transformer architecture.\",\n",
    "            \"mt\": \"Le nouveau modèle est basé sur une architecture de transformateur.\",\n",
    "        }\n",
    "    ],\n",
    "    \"batch_size\": 2\n",
    "}\n",
    "\n",
    "response = predictor.predict(multilingual_input)\n",
    "print(json.dumps(response, indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scores\": [\n",
      "    0.8924700021743774,\n",
      "    0.8798026442527771\n",
      "  ],\n",
      "  \"system_score\": 0.8861363232135773,\n",
      "  \"message\": \"Prediction successful\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing\n",
    "You can process multiple translations at once by adjusting the batch size:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:42:42.486364Z",
     "start_time": "2024-12-06T15:42:41.892166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_input = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"src\": text,\n",
    "            \"mt\": translation,\n",
    "        } for text, translation in [\n",
    "            (\n",
    "                \"The cat sat on the mat.\",\n",
    "                \"Le chat était assis sur le tapis.\",\n",
    "            ),\n",
    "            (\n",
    "                \"I love programming in Python.\",\n",
    "                \"J'aime programmer en Python.\",\n",
    "            ),\n",
    "            (\n",
    "                \"The weather is beautiful today.\",\n",
    "                \"Il fait beau aujourd'hui.\",\n",
    "            )\n",
    "        ]\n",
    "    ],\n",
    "    \"batch_size\": 3\n",
    "}\n",
    "\n",
    "response = predictor.predict(batch_input)\n",
    "print(json.dumps(response, indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scores\": [\n",
      "    0.8695598840713501,\n",
      "    0.8979955315589905,\n",
      "    0.8807777762413025\n",
      "  ],\n",
      "  \"system_score\": 0.882777730623881,\n",
      "  \"message\": \"Prediction successful\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done using the endpoint, to avoid unnecessary costs, you can delete it and the model by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsubscribe to the listing (optional)\n",
    "\n",
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
