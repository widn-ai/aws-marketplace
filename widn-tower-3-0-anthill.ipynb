{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deploy <font color='#6957FF'>Widn Tower Anthill</font> Model Package from AWS Marketplace \n"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tower Anthill** is designed for advanced translation tasks across multiple languages and domains. It excels at translating complex texts while maintaining context and nuance. The model leverages state-of-the-art language modeling techniques to provide high-quality translations that preserve the original meaning and style of the text. It can handle various content types and specialized terminology across different fields. On our validation dataset, Tower Anthill showed better adaptability than other providers and achieved better COMET scores with few-shot (RAG) examples than standard MT providers. 27 languages are explicitly supported: English, Portuguese, Spanish, French, German, Dutch, Italian, Korean, Chinese, Russian, Japanese, Hindi, Ukrainian, Swedish, Polish, Czech, Romanian, Hungarian, Norwegian, Icelandic, Danish.\n",
    "\n",
    "This sample notebook shows you how to deploy <font color='#C9FF33'>[Widn Tower Anthill](https://aws.amazon.com/marketplace/pp/prodview-xskn6yectpscq)</font> using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This model package only supports SageMaker Realtime Inference. Sagemaker doesn't yet support Batch Transform for this type of model package; this is a limitation of the SageMaker Batch Transform service.\n",
    "\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to <font color='#C9FF33'>[Widn Tower Anthill](https://aws.amazon.com/marketplace/pp/prodview-xskn6yectpscq)</font>. If so, skip step [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (by using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Subscribe to the model package"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page <font color='#C9FF33'>[Widn Tower Anthill](https://aws.amazon.com/marketplace/pp/prodview-xskn6yectpscq)</font> in AWS Marketplace.\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:07.166329Z",
     "start_time": "2024-11-06T13:03:07.161366Z"
    }
   },
   "source": [
    "# Set the region to which you subscribed to the model package\n",
    "region = \"us-east-1\"\n",
    "\n",
    "model_package_arn = f\"arn:aws:sagemaker:{region}:571600842260:model-package/widn-tower-3-0-anthill-241001\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you need to load environment variables from a .env file, you can use the following code:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:08.591585Z",
     "start_time": "2024-11-06T13:03:08.581860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install python-dotenv\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:11.143757Z",
     "start_time": "2024-11-06T13:03:10.324566Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from sagemaker import ModelPackage, Predictor, Session\n",
    "from sagemaker import deserializers, get_execution_role, serializers"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/kepler/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:14.964672Z",
     "start_time": "2024-11-06T13:03:13.580729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "session = Session()\n",
    "region = session.boto_region_name\n",
    "role = get_execution_role(session)  # Or directly specify a suitable role\n",
    "role"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::571600842260:role/service-role/AmazonSageMaker-ExecutionRole-20241018T132939'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:18.719528Z",
     "start_time": "2024-11-06T13:03:18.717068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Choose an instance type to run the model\n",
    "instance_type = \"ml.g5.xlarge\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T13:03:23.564807Z",
     "start_time": "2024-11-06T13:03:23.562254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = model_package_arn.split(\"/\")[-1]\n",
    "\n",
    "# Create a deployable model from the model package\n",
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "print(f\"{model_name=}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='widn-tower-3-0-anthill-241001'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Create an endpoint and perform real-time inference"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you want to understand how real-time inference with Amazon SageMaker works, [see their documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Deploy the model\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=model_name,\n",
    "    container_startup_health_check_timeout=500,  # Change if necessary; about 8 minutes is usually enough\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once endpoint has been created, you should be able to perform real-time inference."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the input samples from a jsonlines file in data/input/real-time/source_sentences.jsonl\n",
    "file_name = \"data/input/real-time/source_sentences.jsonl\"\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    inputs = [json.loads(line) for line in f]\n",
    "inputs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Use the following template to create a suitable prompt for translation\n",
    "prompt_template = (\n",
    "    \"\"\"\n",
    "    Translate the following text from {source_language} into {target_language}.\n",
    "    {source_language}: {source_text}\n",
    "    {target_language}:\n",
    "    \"\"\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set whether you'd like a streaming output (or the whole response at once)\n",
    "stream_output = True\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=model_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONLinesDeserializer() if stream_output else deserializers.JSONDeserializer(),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "outputs = (\n",
    "    predictor.predict(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt_template.format(**sample)},\n",
    "            ],\n",
    "            \"max_tokens\": 256,\n",
    "            \"temperature\": 0.0,\n",
    "            \"stream\": stream_output,\n",
    "            # Check available parameters here: https://docs.djl.ai/master/docs/serving/serving/docs/lmi/user_guides/chat_input_output_schema.html#request-schema\n",
    "        }\n",
    "    )\n",
    "    for sample in inputs\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if stream_output:\n",
    "    # Show completion chunks as they come\n",
    "    for output in outputs:\n",
    "        for chunk in output:\n",
    "            print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        print()\n",
    "else:\n",
    "    for output in outputs:\n",
    "        # output is a dictionary with the final response\n",
    "        print(output[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now that you have successfully performed a real-time inference, you do not need the endpoint anymore. You can terminate the endpoint to avoid being charged."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.delete_model()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
